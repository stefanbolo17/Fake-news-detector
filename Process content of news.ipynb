{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 as sql\n",
    "import sys,csv\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sql.connect('./2_Database/work_database_v1.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_sql('SELECT type, content from news where domain != \"beforeitsnews.com\" and domain != \"nytimes.com\" and (type = \"fake\" or type = \"reliable\")',db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT type, content from news', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_ok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-26ddd1122165>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_ok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"final_data_for_model.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_ok' is not defined"
     ]
    }
   ],
   "source": [
    "data_ok.to_csv(\"final_data_for_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ok = pd.concat([df1,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Every college basketball fan knows all too wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>THE WAR HAS BEGUN: The Media Just Attacked Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>VIEW GALLERY\\n\\nThe Boston Celtics are traveli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Gallup released its annual list of the men and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>One of President Donald Trump’s regular pastim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                            content\n",
       "0           0     0  Every college basketball fan knows all too wel...\n",
       "1           1     0  THE WAR HAS BEGUN: The Media Just Attacked Tru...\n",
       "2           2     0  VIEW GALLERY\\n\\nThe Boston Celtics are traveli...\n",
       "3           3     0  Gallup released its annual list of the men and...\n",
       "4           4     0  One of President Donald Trump’s regular pastim..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].map({'fake': 0, 'reliable': 1, 'unreliable': 0, 'conspiracy':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "0    373737\n",
       "1    370524\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of         Unnamed: 0  type                                            content\n",
       "0                0     0  Every college basketball fan knows all too wel...\n",
       "1                1     0  THE WAR HAS BEGUN: The Media Just Attacked Tru...\n",
       "2                2     0  VIEW GALLERY\\n\\nThe Boston Celtics are traveli...\n",
       "3                3     0  Gallup released its annual list of the men and...\n",
       "4                4     0  One of President Donald Trump’s regular pastim...\n",
       "...            ...   ...                                                ...\n",
       "744256      259995     0  Tor\\n\\nTor is an encrypted anonymising network...\n",
       "744257      259996     0  Horry County officials want to make sure the m...\n",
       "744258      259997     0  Raw content\\n\\nLIMITED OFFICIAL USE PAGE 01 VI...\n",
       "744259      259998     0  Tor\\n\\nTor is an encrypted anonymising network...\n",
       "744260      259999     0  By Shamane Mills\\n\\nMadison is receiving $$135...\n",
       "\n",
       "[744261 rows x 3 columns]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = pickle.load(open('./3_Sample/finalized_model-knn.sav', 'rb'))\n",
    "rn_model = pickle.load(open('./3_Sample/finalized_model-rn.sav','rb'))\n",
    "bayes_model = pickle.load(open('./3_Sample/finalized_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87    341207\n",
      "           1       0.92      0.85      0.88    403054\n",
      "\n",
      "    accuracy                           0.88    744261\n",
      "   macro avg       0.88      0.88      0.88    744261\n",
      "weighted avg       0.88      0.88      0.88    744261\n",
      "\n",
      "[[311596  62141]\n",
      " [ 29611 340913]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85    381333\n",
      "           1       0.84      0.86      0.85    362928\n",
      "\n",
      "    accuracy                           0.85    744261\n",
      "   macro avg       0.85      0.85      0.85    744261\n",
      "weighted avg       0.85      0.85      0.85    744261\n",
      "\n",
      "[[322792  50945]\n",
      " [ 58541 311983]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\LICENTA\\Data set\\enviroment\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.50      0.66    744261\n",
      "\n",
      "    accuracy                           0.50    744261\n",
      "   macro avg       0.50      0.25      0.33    744261\n",
      "weighted avg       1.00      0.50      0.66    744261\n",
      "\n",
      "[[     0 373737]\n",
      " [     0 370524]]\n"
     ]
    }
   ],
   "source": [
    "predict_bayes = bayes_model.predict(df['content'])\n",
    "### Score Naiv Bayes\n",
    "\n",
    "print(classification_report(predict_bayes,df['type']))\n",
    "print(confusion_matrix(df['type'], predict_bayes))\n",
    "\n",
    "\n",
    "### Scor KNN\n",
    "\n",
    "predict_knn = knn_model.predict(df['content'])\n",
    "\n",
    "print(classification_report(predict_knn,df['type']))\n",
    "print(confusion_matrix(df['type'], predict_knn))\n",
    "\n",
    "### Scor Retele Neuronale\n",
    "predict_rn = rn_model.predict(df['content'])\n",
    "\n",
    "print(classification_report(predict_rn,df['type']))\n",
    "print(confusion_matrix(df['type'], predict_rn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
