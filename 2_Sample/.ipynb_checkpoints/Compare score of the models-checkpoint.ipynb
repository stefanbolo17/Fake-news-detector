{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import string\n",
    "import nltk # Imports the library\n",
    "import string\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = pickle.load(open('finalized_model-knn.sav', 'rb'))\n",
    "rn_model = pickle.load(open('finalized_model-rn.sav','rb'))\n",
    "bayes_model = pickle.load(open('finalized_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157519 39380 196899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_train, news_test, type_train, type_test = train_test_split(df['content'], df['type'], test_size=0.2)\n",
    "\n",
    "print(len(news_train), len(news_test), len(type_train) + len(type_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','index','sentiment','magnitude','title', 'authors'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikileaks.com</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>Tor\\n\\nTor is an encrypted anonymising network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.yahoo.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>NEW YORK (AP) — Ringling Bros. and Barnum &amp; Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.huffingtonpost.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>The Importance Of Being Kind 11/15/2016 09:44 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thedailysheeple.com</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>Delivered by The Daily Sheeple\\n\\nWe encourage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>fake</td>\n",
       "      <td>What Most Good Investors Do\\n\\n% of readers th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   domain        type  \\\n",
       "0           wikileaks.com  unreliable   \n",
       "1           www.yahoo.com    reliable   \n",
       "2  www.huffingtonpost.com    reliable   \n",
       "3     thedailysheeple.com  conspiracy   \n",
       "4       beforeitsnews.com        fake   \n",
       "\n",
       "                                             content  \n",
       "0  Tor\\n\\nTor is an encrypted anonymising network...  \n",
       "1  NEW YORK (AP) — Ringling Bros. and Barnum & Ba...  \n",
       "2  The Importance Of Being Kind 11/15/2016 09:44 ...  \n",
       "3  Delivered by The Daily Sheeple\\n\\nWe encourage...  \n",
       "4  What Most Good Investors Do\\n\\n% of readers th...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'] = df['type'].map({'fake': 0, 'reliable': 1, 'unreliable': 0, 'conspiracy':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "0    993\n",
       "1    976\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                          domain  type  \\\n",
       "32604    www.huffingtonpost.com     1   \n",
       "49840               nytimes.com     1   \n",
       "26766               nytimes.com     1   \n",
       "28471         beforeitsnews.com     0   \n",
       "11150   conservativerefocus.com     0   \n",
       "...                         ...   ...   \n",
       "33969               nytimes.com     1   \n",
       "35123            wikispooks.com     0   \n",
       "107383              nytimes.com     1   \n",
       "61785        abovetopsecret.com     0   \n",
       "105644           abcnews.go.com     1   \n",
       "\n",
       "                                                  content  \n",
       "32604   starzfly/Bauer-Griffin via Getty Images “It’s ...  \n",
       "49840   THIS delicate dish of finely diced mushrooms a...  \n",
       "26766   WHAT could be more pleasurable than a midsumme...  \n",
       "28471   Hormel Foods Reduces Water Use by 30 Million G...  \n",
       "11150   Anyone else notice that No one ever needs to g...  \n",
       "...                                                   ...  \n",
       "33969   KRYSTAL--Solomon. The Board of Directors and S...  \n",
       "35123   \"Query depth\" is a predefined property that in...  \n",
       "107383  4. BUZZARDS BAY, MASS.\\n\\nYou could join the s...  \n",
       "61785   I swear to you it is absolutely real. My name ...  \n",
       "105644  Email A jury has reached a guilty verdict in t...  \n",
       "\n",
       "[1969 rows x 3 columns]>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_bayes = bayes_model.predict(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_knn = knn_model.predict(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rn = rn_model.predict(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Naiv Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       876\n",
      "           1       0.99      0.88      0.93      1093\n",
      "\n",
      "    accuracy                           0.93      1969\n",
      "   macro avg       0.93      0.93      0.93      1969\n",
      "weighted avg       0.93      0.93      0.93      1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict_bayes,df['type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scor KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       954\n",
      "           1       0.94      0.90      0.92      1015\n",
      "\n",
      "    accuracy                           0.92      1969\n",
      "   macro avg       0.92      0.92      0.92      1969\n",
      "weighted avg       0.92      0.92      0.92      1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict_knn,df['type']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scor Retele Neuronale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       991\n",
      "           1       0.99      0.99      0.99       978\n",
      "\n",
      "    accuracy                           0.99      1969\n",
      "   macro avg       0.99      0.99      0.99      1969\n",
      "weighted avg       0.99      0.99      0.99      1969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predict_rn,df['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'param_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-ef1c124fac31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayes_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dask'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler_host\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'your_scheduler_host:your_port'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'param_distributions'"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.joblib import parallel_backend\n",
    "\n",
    "search = RandomizedSearchCV(bayes_model, param_space, cv=10, n_iter=1000, verbose=1)\n",
    "\n",
    "with parallel_backend('dask', scheduler_host='your_scheduler_host:your_port'):\n",
    "        search.fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.9 ms ± 2.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit NMF(n_components=8, tol=1e-2).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
